{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab109ba-0cb9-4c10-9aab-10462068df71",
   "metadata": {},
   "source": [
    "# Duck Hunting\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Resumen:</b> El código desarrolla un método para detectar y localizar un objeto específico dentro de una imagen mediante la técnica de correlación cruzada entre una plantilla (objeto) y una imagen de fondo.\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "## Contenido\n",
    "\n",
    "1. Preámbulo\n",
    "2. Lectura del fondo\n",
    "3. Lectura del personaje\n",
    "4. Correlación entre el personaje y el fondo\n",
    "5. Fusión de las mediciones de correlación\n",
    "6. Mapa de correlación\n",
    "    - 6.1 Mapa de corelación 2D\n",
    "    - 6.2 Mapa de corelació 3D\n",
    "7. Coordenadas de la máxima correlación\n",
    "8. Visualización del resultado\n",
    "9. Preguntas orientadoras\n",
    "10. Actividades\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5f3cc5-8fa9-4e7f-8b27-94c6a28d4218",
   "metadata": {},
   "source": [
    "## 1. Preámbulo\n",
    "\n",
    "Importamos las librerías necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236c2a95-70e6-4b69-8de3-a1d45a74b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e703cf1-545d-44f7-b511-6710408e4d0a",
   "metadata": {},
   "source": [
    "## 2. Lectura de la imagen de fondo\n",
    "Leemos la imagen de fondo y se muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e31bf11-a07e-47e8-bc4e-d8ba0f3da933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de la imagen de fondo\n",
    "im_bg = cv2.imread(\"duck_hunt_1.png\")\n",
    "im_bg_float = im_bg.astype(np.float32)/255.0\n",
    "\n",
    "# Convertimos de BGR a RGB para mostrar correctamente con matplotlib\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cv2.cvtColor(im_bg, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Imagen de fondo\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4866ddd1-a05f-483e-bea7-152f7c94f147",
   "metadata": {},
   "source": [
    "# 3. Lectura del personaje\n",
    "Leemos la imagen del personaje (pato)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca772b2-4659-4b09-8fe8-aaf7fe5f7ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de la imagen del personaje\n",
    "im_duck = cv2.imread(\"duck_1.png\")\n",
    "im_duck_float = im_duck.astype(np.float32)/255.0\n",
    "\n",
    "# Convertimos de BGR a RGB para mostrar correctamente con matplotlib\n",
    "plt.figure(figsize=(3, 2))\n",
    "plt.imshow(cv2.cvtColor(im_duck, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Imagen del personaje\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827b5b8d-760a-49ee-a2eb-502f7105bcf3",
   "metadata": {},
   "source": [
    "## 4. Correlación entre el personaje y el fondo\n",
    "Realizamos la correlación entre las imágenes en cada canal de color:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b375efa-acec-42cc-9e22-827f105b6b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación en el canal Rojo\n",
    "duck_corr_r = cv2.filter2D(im_bg_float[:, :, 2], -1, im_duck_float[:, :, 2], borderType=cv2.BORDER_CONSTANT)\n",
    "\n",
    "# Correlación en el canal Verde\n",
    "duck_corr_g = cv2.filter2D(im_bg_float[:, :, 1], -1, im_duck_float[:, :, 1], borderType=cv2.BORDER_CONSTANT)\n",
    "\n",
    "# Correlación en el canal Azul\n",
    "duck_corr_b = cv2.filter2D(im_bg_float[:, :, 0], -1, im_duck_float[:, :, 0], borderType=cv2.BORDER_CONSTANT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bde3384-fb7c-4025-8dad-acbdfb6c90fe",
   "metadata": {},
   "source": [
    "## 5. Fusión de las mediciones de correlación\n",
    "Fusionamos las mediciones de correlación de los tres canales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88358310-9b16-4596-b6a1-af080a7a329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_corr_rgb = np.sqrt(duck_corr_r**2 + duck_corr_g**2 + duck_corr_b**2)\n",
    "print(\"Valor máximo de correlación:\", np.max(duck_corr_rgb))\n",
    "print(\"Valor minimo de correlación:\", np.min(duck_corr_rgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a32b84-da24-4a08-b816-d0a29593b45c",
   "metadata": {},
   "source": [
    "## 6. Mapa de correlación\n",
    "\n",
    "### 6.1 Normalización del mapa de correlación\n",
    "\n",
    "Antes de mostrar el mapa de correlación, lo normalizamos para que los valores estén en el rango [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790fd3ae-ce83-481b-a30d-1e04de6583a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos el mapa de correlación\n",
    "min_corr = np.min(duck_corr_rgb)\n",
    "max_corr = np.max(duck_corr_rgb)\n",
    "duck_corr_rgb_norm = (duck_corr_rgb - min_corr) / (max_corr - min_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e793b592-1d06-46a3-9b9d-3ae8c8289df5",
   "metadata": {},
   "source": [
    "### 6.2 Mapa de correlación en 2D\n",
    "\n",
    "Mostramos el mapa de correlación invertido en 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a02669-a526-433f-a372-452d406e1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(duck_corr_rgb_norm, cmap='gray')\n",
    "plt.title(\"Mapa de correlación (2D)\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3d29f0-b15f-421a-8737-f6b10a8799c8",
   "metadata": {},
   "source": [
    "### 6.3 Mapa de correlación 3D\n",
    "\n",
    "Mostramos el mapa de correlación 3D, invertimos la imagen para ajustarla con los ejes del plano 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac4ea9-49a5-4e5c-9d93-d9fb51f7d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invertimos verticalmente el mapa de correlación normalizado\n",
    "duck_corr_rgb_norm_flipped = np.flipud(duck_corr_rgb_norm)\n",
    "\n",
    "# Submuestreamos para reducir la cantidad de datos\n",
    "duck_corr_norm_ds = duck_corr_rgb_norm_flipped[::2, ::2]\n",
    "\n",
    "# Creamos una malla de coordenadas\n",
    "X, Y = np.meshgrid(np.arange(duck_corr_norm_ds.shape[1]), np.arange(duck_corr_norm_ds.shape[0]))\n",
    "\n",
    "# Graficamos la superficie\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X, Y, duck_corr_norm_ds, cmap='viridis')\n",
    "ax.set_title(\"Mapa de correlación normalizado (3D)\")\n",
    "# Rotamos la figura 3D\n",
    "ax.view_init(elev=25, azim=-85)  # Puedes ajustar 'elev' y 'azim' para cambiar la vista\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba11581-a40e-4fcd-af99-c364d7c38599",
   "metadata": {},
   "source": [
    "## 7. Coordenadas de la máxima correlación\n",
    "\n",
    "Encontramos las coordenadas donde la correlación es máxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055e1dc-7085-4fc0-b725-764ab10edb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_corr = np.max(duck_corr_r)\n",
    "indices = np.where(duck_corr_r == max_corr)\n",
    "r = indices[0][0]\n",
    "c = indices[1][0]\n",
    "print(f\"Coordenadas de máxima correlación: r = {r}, c = {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aadd5a-ee79-4853-85b2-d1a19468be5e",
   "metadata": {},
   "source": [
    "## 8. Visualización del resultado\n",
    "\n",
    "Utilizamos la función cv2.rectangle de OpenCV para dibujar un recuadro en la posición encontrada, utilizando el tamaño de la imagen del pato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8457605f-58ab-4f21-b889-4cc39ac1cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una copia de la imagen de fondo para dibujar el resultado\n",
    "im_bg_result = im_bg.copy()\n",
    "\n",
    "# Obtenemos el tamaño de la imagen del pato\n",
    "duck_height, duck_width = im_duck.shape[:2]\n",
    "\n",
    "# Coordenadas del rectángulo\n",
    "top_left = (c - duck_width//2, r - duck_height//2)\n",
    "bottom_right = (c + duck_width//2, r + duck_height//2)\n",
    "\n",
    "# Nos aseguramos de que las coordenadas estén dentro de los límites de la imagen\n",
    "top_left = (max(top_left[0], 0), max(top_left[1], 0))\n",
    "bottom_right = (min(bottom_right[0], im_bg_result.shape[1]-1), min(bottom_right[1], im_bg_result.shape[0]-1))\n",
    "\n",
    "# Dibujamos el rectángulo en la imagen\n",
    "cv2.rectangle(im_bg_result, top_left, bottom_right, color=(0, 0, 255), thickness=2)  # Color rojo en BGR\n",
    "\n",
    "# Mostramos la imagen con la posición marcada\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cv2.cvtColor(im_bg_result, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Resultado final\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d52f58-5ee9-4689-b9db-72e9b5c9c713",
   "metadata": {},
   "source": [
    "## 9. Preguntas orientadoras\n",
    "\n",
    "<b>Mejora de la precisión:</b>\n",
    "\n",
    "- ¿De qué manera podemos ajustar la regla de fusión para mejorar la detección del objeto?\n",
    "- ¿Qué sucede si cambiamos los pesos asignados a los canales de color en la fusión de las correlaciones?\n",
    "\n",
    "<b>Escalabilidad y robustez:</b>\n",
    "\n",
    "- ¿Cómo podemos adaptar el código para detectar objetos de diferentes tamaños o rotaciones?\n",
    "- ¿Es posible implementar una técnica de correlación multiescala o rotacionalmente invariante?\n",
    "\n",
    "<b>Preprocesamiento de imágenes:</b>\n",
    "\n",
    "- ¿Qué técnicas de preprocesamiento (como filtrado, ecualización de histograma, normalización) podrían mejorar la calidad de la correlación?\n",
    "- ¿Deberíamos considerar la conversión a otros espacios de color (como HSV o Lab) para mejorar la detección?\n",
    "\n",
    "<b>Gestión de ruido y artefactos:</b>\n",
    "\n",
    "- ¿Cómo afecta el ruido en las imágenes a la correlación y cómo podemos mitigarlo?\n",
    "- ¿Podemos aplicar filtros pasa-bajos o técnicas de reducción de ruido antes de la correlación?\n",
    "\n",
    "<b>Automatización y generalización:</b>\n",
    "\n",
    "- ¿Cómo podemos automatizar la detección para múltiples objetos o patrones diferentes en la misma imagen?\n",
    "- ¿Es posible entrenar un modelo que aprenda características más generales del objeto para mejorar la detección?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ead068e-966d-48d9-9d9a-928e1e81c91b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Actividades\n",
    "\n",
    "<b>Ajustar la regla de fusión:</b>\n",
    "\n",
    "- Actividad: Experimentar con diferentes pesos en la fusión de las correlaciones de los canales de color para observar cómo afecta a la detección del objeto.\n",
    "- Modificación: Modificar los coeficientes en la ecuación de fusión.\n",
    "\n",
    "<b>Cambiar el objeto de detección:</b>\n",
    "\n",
    "- Actividad: Sustituir la imagen del pato por otra imagen de un objeto diferente (por ejemplo, el otro pato, etc.) y ajustar el código para detectar este nuevo objeto en la imagen de fondo.\n",
    "- Modificación: Actualizar las rutas de las imágenes y, si es necesario, ajustar los pesos en la regla de fusión para adaptarse al nuevo objeto.\n",
    "\n",
    "<b>Implementar una Región de Interés (ROI):</b>\n",
    "\n",
    "- Actividad: Limitar el área de búsqueda a una región específica de la imagen de fondo para mejorar la eficiencia y la precisión de la detección.\n",
    "- Modificación: Definir coordenadas para la ROI y aplicar la correlación únicamente dentro de esa región."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2-kernel",
   "language": "python",
   "name": "cv2-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
